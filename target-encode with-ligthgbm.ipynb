{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target encoding and training a lightGBM Model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this section I will perform ordinal encoding on variable 'size' and target encoding on categorical features 'brand', 'material', 'style' and 'color'. This approach was choosen given the hierarchical nature of 'size' feature. Target encoding on the rest of categorical variables was done using TargetEncoder from category_encoders library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: category_encoders in /opt/anaconda3/lib/python3.11/site-packages (2.8.0)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /opt/anaconda3/lib/python3.11/site-packages (from category_encoders) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.0.5 in /opt/anaconda3/lib/python3.11/site-packages (from category_encoders) (2.1.4)\n",
      "Requirement already satisfied: patsy>=0.5.1 in /opt/anaconda3/lib/python3.11/site-packages (from category_encoders) (0.5.3)\n",
      "Requirement already satisfied: scikit-learn>=1.6.0 in /opt/anaconda3/lib/python3.11/site-packages (from category_encoders) (1.6.1)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from category_encoders) (1.11.4)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in /opt/anaconda3/lib/python3.11/site-packages (from category_encoders) (0.14.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.11/site-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas>=1.0.5->category_encoders) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas>=1.0.5->category_encoders) (2023.3)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.11/site-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn>=1.6.0->category_encoders) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn>=1.6.0->category_encoders) (3.5.0)\n",
      "Requirement already satisfied: packaging>=21.3 in /opt/anaconda3/lib/python3.11/site-packages (from statsmodels>=0.9.0->category_encoders) (23.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in /opt/anaconda3/lib/python3.11/site-packages (4.2.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /opt/anaconda3/lib/python3.11/site-packages (from optuna) (1.14.1)\n",
      "Requirement already satisfied: colorlog in /opt/anaconda3/lib/python3.11/site-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.11/site-packages (from optuna) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.11/site-packages (from optuna) (23.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /opt/anaconda3/lib/python3.11/site-packages (from optuna) (2.0.25)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.11/site-packages (from optuna) (4.65.0)\n",
      "Requirement already satisfied: PyYAML in /opt/anaconda3/lib/python3.11/site-packages (from optuna) (6.0.1)\n",
      "Requirement already satisfied: Mako in /opt/anaconda3/lib/python3.11/site-packages (from alembic>=1.5.0->optuna) (1.3.9)\n",
      "Requirement already satisfied: typing-extensions>=4 in /opt/anaconda3/lib/python3.11/site-packages (from alembic>=1.5.0->optuna) (4.9.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from sqlalchemy>=1.4.2->optuna) (3.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/anaconda3/lib/python3.11/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in /opt/anaconda3/lib/python3.11/site-packages (4.5.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/anaconda3/lib/python3.11/site-packages (from lightgbm) (1.26.4)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.11/site-packages (from lightgbm) (1.11.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cat_backpack.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 300000 entries, 0 to 299999\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   id                  300000 non-null  int64  \n",
      " 1   brand               300000 non-null  object \n",
      " 2   material            300000 non-null  object \n",
      " 3   size                300000 non-null  object \n",
      " 4   compartments        300000 non-null  int64  \n",
      " 5   laptop_compartment  300000 non-null  bool   \n",
      " 6   waterproof          300000 non-null  bool   \n",
      " 7   style               300000 non-null  object \n",
      " 8   color               300000 non-null  object \n",
      " 9   weight_cap          300000 non-null  float64\n",
      " 10  Price               300000 non-null  float64\n",
      "dtypes: bool(2), float64(2), int64(2), object(5)\n",
      "memory usage: 21.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>brand</th>\n",
       "      <th>material</th>\n",
       "      <th>size</th>\n",
       "      <th>compartments</th>\n",
       "      <th>laptop_compartment</th>\n",
       "      <th>waterproof</th>\n",
       "      <th>style</th>\n",
       "      <th>color</th>\n",
       "      <th>weight_cap</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>222806</th>\n",
       "      <td>222806</td>\n",
       "      <td>Puma</td>\n",
       "      <td>Nylon</td>\n",
       "      <td>Large</td>\n",
       "      <td>10</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Pink</td>\n",
       "      <td>29.457056</td>\n",
       "      <td>125.96579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155198</th>\n",
       "      <td>155198</td>\n",
       "      <td>Adidas</td>\n",
       "      <td>Canvas</td>\n",
       "      <td>Medium</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Messenger</td>\n",
       "      <td>Gray</td>\n",
       "      <td>8.432289</td>\n",
       "      <td>85.44422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298917</th>\n",
       "      <td>298917</td>\n",
       "      <td>Jansport</td>\n",
       "      <td>Nylon</td>\n",
       "      <td>Small</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Tote</td>\n",
       "      <td>Black</td>\n",
       "      <td>20.077096</td>\n",
       "      <td>128.88365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15641</th>\n",
       "      <td>15641</td>\n",
       "      <td>Adidas</td>\n",
       "      <td>Leather</td>\n",
       "      <td>Large</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Backpack</td>\n",
       "      <td>Black</td>\n",
       "      <td>17.483045</td>\n",
       "      <td>27.85988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62573</th>\n",
       "      <td>62573</td>\n",
       "      <td>Puma</td>\n",
       "      <td>Leather</td>\n",
       "      <td>Small</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Messenger</td>\n",
       "      <td>Gray</td>\n",
       "      <td>22.898382</td>\n",
       "      <td>40.00212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id     brand material    size  compartments  laptop_compartment  \\\n",
       "222806  222806      Puma    Nylon   Large            10               False   \n",
       "155198  155198    Adidas   Canvas  Medium             9               False   \n",
       "298917  298917  Jansport    Nylon   Small             6               False   \n",
       "15641    15641    Adidas  Leather   Large             3                True   \n",
       "62573    62573      Puma  Leather   Small             5               False   \n",
       "\n",
       "        waterproof      style  color  weight_cap      Price  \n",
       "222806        True    Unknown   Pink   29.457056  125.96579  \n",
       "155198       False  Messenger   Gray    8.432289   85.44422  \n",
       "298917       False       Tote  Black   20.077096  128.88365  \n",
       "15641         True   Backpack  Black   17.483045   27.85988  \n",
       "62573        False  Messenger   Gray   22.898382   40.00212  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ordinal encoding for size feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to map size categories to numerical values\n",
    "size_mapping = {\n",
    "    'Small': 0,\n",
    "    'Medium': 1,\n",
    "    'Large': 2,\n",
    "    'Unknown': 3  # Or you can assign it -1 or another distinct value\n",
    "}\n",
    "\n",
    "# Apply the mapping to the 'size' column\n",
    "df['size_encoded'] = df['size'].map(size_mapping)\n",
    "\n",
    "# Drop the original 'size' column (optional)\n",
    "df.drop('size', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 300000 entries, 0 to 299999\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   id                  300000 non-null  int64  \n",
      " 1   brand               300000 non-null  object \n",
      " 2   material            300000 non-null  object \n",
      " 3   compartments        300000 non-null  int64  \n",
      " 4   laptop_compartment  300000 non-null  bool   \n",
      " 5   waterproof          300000 non-null  bool   \n",
      " 6   style               300000 non-null  object \n",
      " 7   color               300000 non-null  object \n",
      " 8   weight_cap          300000 non-null  float64\n",
      " 9   Price               300000 non-null  float64\n",
      " 10  size_encoded        300000 non-null  int64  \n",
      "dtypes: bool(2), float64(2), int64(3), object(4)\n",
      "memory usage: 21.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Target encoding for 'brand', 'material', 'style' and 'color'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and target (y)\n",
    "X = df.drop(['Price'], axis=1)  # Exclude 'Price' column\n",
    "y = df['Price']\n",
    "# drop id column\n",
    "X = X.drop('id', axis=1)\n",
    "\n",
    "# List of categorical features to encode\n",
    "categorical_features = ['brand', 'material', 'style', 'color']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and fit the TargetEncoder\n",
    "encoder = TargetEncoder(cols=categorical_features)\n",
    "\n",
    "# Fit the encoder on the training data and transform both training and testing data\n",
    "X_train_encoded = encoder.fit_transform(X_train, y_train)\n",
    "X_test_encoded = encoder.transform(X_test)\n",
    "\n",
    "# Now X_train_encoded and X_test_encoded have the categorical features target encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            brand   material  compartments  laptop_compartment  waterproof  \\\n",
      "272417  81.956967  82.028371             7                True        True   \n",
      "200398  81.858243  82.028371             1                True        True   \n",
      "275984  81.956967  80.479359            10                True        True   \n",
      "284883  81.956967  81.072777             3               False        True   \n",
      "150286  81.956967  81.072777             7               False       False   \n",
      "\n",
      "            style      color  weight_cap  size_encoded  \n",
      "272417  81.432036  81.803978   22.315614             2  \n",
      "200398  81.430891  81.675616   28.567489             0  \n",
      "275984  81.432036  82.409704   24.579628             2  \n",
      "284883  81.417545  81.803978   14.279998             1  \n",
      "150286  81.417545  82.010883   26.893251             2  \n"
     ]
    }
   ],
   "source": [
    "print(X_train_encoded.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Root Mean Squared Error (RMSE): 38.922589913117605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the training data and transform both training and testing data\n",
    "X_train_scaled = scaler.fit_transform(X_train_encoded)\n",
    "X_test_scaled = scaler.transform(X_test_encoded)\n",
    "\n",
    "# Create a LightGBM regressor object\n",
    "model = lgb.LGBMRegressor()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions using the scaled test data\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"Base Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002071 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 303\n",
      "[LightGBM] [Info] Number of data points in the train set: 240000, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 81.448481\n",
      "Root Mean Squared Error (RMSE): 38.922589913117605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the training data and transform both training and testing data\n",
    "X_train_scaled = scaler.fit_transform(X_train_encoded)\n",
    "X_test_scaled = scaler.transform(X_test_encoded)\n",
    "\n",
    "# Create a LightGBM regressor object\n",
    "model = lgb.LGBMRegressor()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions using the scaled test data\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the training data and transform both training and testing data\n",
    "X_train_scaled = scaler.fit_transform(X_train_encoded)\n",
    "X_test_scaled = scaler.transform(X_test_encoded)\n",
    "\n",
    "def objective(trial):\n",
    "    # Define the hyperparameters to tune\n",
    "    param = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'verbosity': -1,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n",
    "        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 0.1),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000)\n",
    "    }\n",
    "\n",
    "    # Create a LightGBM regressor object with the hyperparameters\n",
    "    model = lgb.LGBMRegressor(**param)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Make predictions using the scaled test data\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    # Calculate RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    return rmse\n",
    "\n",
    "# Run the Optuna study\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Final Root Mean Squared Error (RMSE): 38.90398143180675\n",
    "- Best trial: 38.90398143180675\n",
    "\n",
    "- Best hyperparameters: {'lambda_l1': 1.6229992273231575e-06, 'lambda_l2': 0.0005641642076268367, 'num_leaves': 16, 'feature_fraction': 0.42662487262370474, 'bagging_fraction': 0.931976901981435, 'bagging_freq': 5, 'min_child_samples': 9, 'learning_rate': 0.015392905483155068, 'n_estimators': 766}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: 38.9081140448483\n",
      "Best hyperparameters: {'lambda_l1': 1.4543158394093417e-07, 'lambda_l2': 1.2972059993778709e-05, 'num_leaves': 21, 'feature_fraction': 0.48555572721680923, 'bagging_fraction': 0.6752773982027428, 'bagging_freq': 7, 'min_child_samples': 88, 'learning_rate': 0.01001847056153441, 'n_estimators': 922}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Root Mean Squared Error (RMSE): 38.9081140448483\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best trial: {study.best_trial.value}\")\n",
    "print(f\"Best hyperparameters: {study.best_trial.params}\")\n",
    "\n",
    "# Train the final model with the best hyperparameters\n",
    "best_params = study.best_trial.params\n",
    "\n",
    "# Create a LightGBM regressor object with the best hyperparameters\n",
    "model = lgb.LGBMRegressor(**best_params)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions using the scaled test data\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"Final Root Mean Squared Error (RMSE): {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lowest rMSE obtained from this attempt was 38.9081 which still fell short from competition winner(38.82013). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
