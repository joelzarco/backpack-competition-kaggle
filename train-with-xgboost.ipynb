{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this secttion I will attempt to minimize rMSE by using the XGBoost regressor and fine tunning it using the Optuna library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: category_encoders in /opt/anaconda3/lib/python3.11/site-packages (2.8.0)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /opt/anaconda3/lib/python3.11/site-packages (from category_encoders) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.0.5 in /opt/anaconda3/lib/python3.11/site-packages (from category_encoders) (2.1.4)\n",
      "Requirement already satisfied: patsy>=0.5.1 in /opt/anaconda3/lib/python3.11/site-packages (from category_encoders) (0.5.3)\n",
      "Requirement already satisfied: scikit-learn>=1.6.0 in /opt/anaconda3/lib/python3.11/site-packages (from category_encoders) (1.6.1)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from category_encoders) (1.11.4)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in /opt/anaconda3/lib/python3.11/site-packages (from category_encoders) (0.14.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.11/site-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas>=1.0.5->category_encoders) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas>=1.0.5->category_encoders) (2023.3)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.11/site-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn>=1.6.0->category_encoders) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn>=1.6.0->category_encoders) (3.5.0)\n",
      "Requirement already satisfied: packaging>=21.3 in /opt/anaconda3/lib/python3.11/site-packages (from statsmodels>=0.9.0->category_encoders) (23.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in /opt/anaconda3/lib/python3.11/site-packages (4.2.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /opt/anaconda3/lib/python3.11/site-packages (from optuna) (1.14.1)\n",
      "Requirement already satisfied: colorlog in /opt/anaconda3/lib/python3.11/site-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.11/site-packages (from optuna) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.11/site-packages (from optuna) (23.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /opt/anaconda3/lib/python3.11/site-packages (from optuna) (2.0.25)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.11/site-packages (from optuna) (4.65.0)\n",
      "Requirement already satisfied: PyYAML in /opt/anaconda3/lib/python3.11/site-packages (from optuna) (6.0.1)\n",
      "Requirement already satisfied: Mako in /opt/anaconda3/lib/python3.11/site-packages (from alembic>=1.5.0->optuna) (1.3.9)\n",
      "Requirement already satisfied: typing-extensions>=4 in /opt/anaconda3/lib/python3.11/site-packages (from alembic>=1.5.0->optuna) (4.9.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from sqlalchemy>=1.4.2->optuna) (3.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/anaconda3/lib/python3.11/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /opt/anaconda3/lib/python3.11/site-packages (2.1.4)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.11/site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.11/site-packages (from xgboost) (1.11.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install XGBoost\n",
    "%pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "import pandas as pd\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import optuna\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Categorical features will be encoded using TargetEncoder as it was done in the previous test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cat_backpack.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>brand</th>\n",
       "      <th>material</th>\n",
       "      <th>size</th>\n",
       "      <th>compartments</th>\n",
       "      <th>laptop_compartment</th>\n",
       "      <th>waterproof</th>\n",
       "      <th>style</th>\n",
       "      <th>color</th>\n",
       "      <th>weight_cap</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>174410</th>\n",
       "      <td>174410</td>\n",
       "      <td>Puma</td>\n",
       "      <td>Polyester</td>\n",
       "      <td>Large</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Messenger</td>\n",
       "      <td>Gray</td>\n",
       "      <td>9.536959</td>\n",
       "      <td>72.19629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207296</th>\n",
       "      <td>207296</td>\n",
       "      <td>Adidas</td>\n",
       "      <td>Nylon</td>\n",
       "      <td>Large</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>Tote</td>\n",
       "      <td>Red</td>\n",
       "      <td>28.777509</td>\n",
       "      <td>55.18705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151731</th>\n",
       "      <td>151731</td>\n",
       "      <td>Adidas</td>\n",
       "      <td>Polyester</td>\n",
       "      <td>Small</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Messenger</td>\n",
       "      <td>Pink</td>\n",
       "      <td>18.812184</td>\n",
       "      <td>42.12754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197471</th>\n",
       "      <td>197471</td>\n",
       "      <td>Adidas</td>\n",
       "      <td>Leather</td>\n",
       "      <td>Small</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Tote</td>\n",
       "      <td>Red</td>\n",
       "      <td>18.936837</td>\n",
       "      <td>144.18475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257544</th>\n",
       "      <td>257544</td>\n",
       "      <td>Nike</td>\n",
       "      <td>Polyester</td>\n",
       "      <td>Large</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Backpack</td>\n",
       "      <td>Gray</td>\n",
       "      <td>19.281521</td>\n",
       "      <td>89.63150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id   brand   material   size  compartments  laptop_compartment  \\\n",
       "174410  174410    Puma  Polyester  Large             8               False   \n",
       "207296  207296  Adidas      Nylon  Large             4                True   \n",
       "151731  151731  Adidas  Polyester  Small             2                True   \n",
       "197471  197471  Adidas    Leather  Small            10                True   \n",
       "257544  257544    Nike  Polyester  Large             8                True   \n",
       "\n",
       "        waterproof      style color  weight_cap      Price  \n",
       "174410       False  Messenger  Gray    9.536959   72.19629  \n",
       "207296        True       Tote   Red   28.777509   55.18705  \n",
       "151731       False  Messenger  Pink   18.812184   42.12754  \n",
       "197471       False       Tote   Red   18.936837  144.18475  \n",
       "257544       False   Backpack  Gray   19.281521   89.63150  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ordinal encoding for 'size' feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to map size categories to numerical values\n",
    "size_mapping = {\n",
    "    'Small': 0,\n",
    "    'Medium': 1,\n",
    "    'Large': 2,\n",
    "    'Unknown': 3  # Or you can assign it -1 or another distinct value\n",
    "}\n",
    "\n",
    "# Apply the mapping to the 'size' column\n",
    "df['size_encoded'] = df['size'].map(size_mapping)\n",
    "\n",
    "# Drop the original 'size' column (optional)\n",
    "df.drop('size', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Target encoding for 'brand', 'material', 'style' and 'color'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and target (y)\n",
    "X = df.drop(['Price', 'id'], axis=1)  # Exclude 'Price' column\n",
    "y = df['Price']\n",
    "\n",
    "# List of categorical features to encode\n",
    "categorical_features = ['brand', 'material', 'style', 'color']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and fit the TargetEncoder\n",
    "encoder = TargetEncoder(cols=categorical_features)\n",
    "\n",
    "# Fit the encoder on the training data and transform both training and testing data\n",
    "X_train_encoded = encoder.fit_transform(X_train, y_train)\n",
    "X_test_encoded = encoder.transform(X_test)\n",
    "\n",
    "# Now X_train_encoded and X_test_encoded have the categorical features target encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>material</th>\n",
       "      <th>compartments</th>\n",
       "      <th>laptop_compartment</th>\n",
       "      <th>waterproof</th>\n",
       "      <th>style</th>\n",
       "      <th>color</th>\n",
       "      <th>weight_cap</th>\n",
       "      <th>size_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>126206</th>\n",
       "      <td>81.333835</td>\n",
       "      <td>80.479359</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>81.430891</td>\n",
       "      <td>81.014828</td>\n",
       "      <td>20.585557</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157868</th>\n",
       "      <td>81.587360</td>\n",
       "      <td>82.028371</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>81.430891</td>\n",
       "      <td>81.014828</td>\n",
       "      <td>21.958857</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30206</th>\n",
       "      <td>81.858243</td>\n",
       "      <td>82.028371</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>81.432036</td>\n",
       "      <td>81.675616</td>\n",
       "      <td>8.837172</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100616</th>\n",
       "      <td>81.956967</td>\n",
       "      <td>80.479359</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>81.430891</td>\n",
       "      <td>80.985014</td>\n",
       "      <td>11.967720</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143136</th>\n",
       "      <td>81.333835</td>\n",
       "      <td>80.479359</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>81.430891</td>\n",
       "      <td>82.010883</td>\n",
       "      <td>23.985510</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            brand   material  compartments  laptop_compartment  waterproof  \\\n",
       "126206  81.333835  80.479359             1               False       False   \n",
       "157868  81.587360  82.028371             9               False        True   \n",
       "30206   81.858243  82.028371             5               False        True   \n",
       "100616  81.956967  80.479359             8                True       False   \n",
       "143136  81.333835  80.479359             9               False       False   \n",
       "\n",
       "            style      color  weight_cap  size_encoded  \n",
       "126206  81.430891  81.014828   20.585557             2  \n",
       "157868  81.430891  81.014828   21.958857             0  \n",
       "30206   81.432036  81.675616    8.837172             1  \n",
       "100616  81.430891  80.985014   11.967720             2  \n",
       "143136  81.430891  82.010883   23.985510             0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_train_encoded.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train and evaluate an XGBoost regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_encoded)\n",
    "X_test_scaled = scaler.transform(X_test_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:55:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 38.91025938703038\n"
     ]
    }
   ],
   "source": [
    "# Create DMatrix for XGBoost\n",
    "dtrain = xgb.DMatrix(X_train_scaled, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test_scaled, label=y_test)\n",
    "\n",
    "# Set XGBoost parameters\n",
    "params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'max_depth': 3,\n",
    "    'learning_rate': 0.1,\n",
    "    'n_estimators': 100\n",
    "}\n",
    "\n",
    "# Train the XGBoost model\n",
    "model = xgb.train(params, dtrain, num_boost_round=100)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(dtest)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mse ** 0.5\n",
    "\n",
    "print(f\"Root Mean Squared Error: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fine tune the hyperparameters of the XGBoost model using Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Define the hyperparameter search space\n",
    "    param = {\n",
    "        'objective': 'reg:squarederror',\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'alpha': trial.suggest_float('alpha', 0, 10),\n",
    "        'lambda': trial.suggest_float('lambda', 0, 10)\n",
    "    }\n",
    "\n",
    "    # Create DMatrix for XGBoost\n",
    "    dtrain = xgb.DMatrix(X_train_scaled, label=y_train)\n",
    "    dtest = xgb.DMatrix(X_test_scaled, label=y_test)\n",
    "\n",
    "    # Train the XGBoost model\n",
    "    model = xgb.train(param, dtrain, num_boost_round=100)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = model.predict(dtest)\n",
    "\n",
    "    # Evaluate the model\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-17 11:55:16,847] A new study created in memory with name: no-name-ef1743be-56c6-412c-b315-812be811a048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:55:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:55:20,310] Trial 0 finished with value: 1523.0372416276668 and parameters: {'max_depth': 10, 'learning_rate': 0.06146518304224565, 'n_estimators': 200, 'subsample': 0.835923168705416, 'colsample_bytree': 0.6967638322420567, 'alpha': 6.798346014464882, 'lambda': 1.0724610637442444}. Best is trial 0 with value: 1523.0372416276668.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:55:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:55:22,845] Trial 1 finished with value: 1517.5700537262016 and parameters: {'max_depth': 9, 'learning_rate': 0.0419615147205333, 'n_estimators': 214, 'subsample': 0.5772728959171824, 'colsample_bytree': 0.8455375144490951, 'alpha': 4.941307209988421, 'lambda': 7.244740059451232}. Best is trial 1 with value: 1517.5700537262016.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:55:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:55:24,642] Trial 2 finished with value: 1526.2160832159934 and parameters: {'max_depth': 7, 'learning_rate': 0.19236146554896386, 'n_estimators': 109, 'subsample': 0.9132202836766146, 'colsample_bytree': 0.8126449932073769, 'alpha': 2.8078217825771477, 'lambda': 3.879359005678528}. Best is trial 1 with value: 1517.5700537262016.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:55:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:55:26,160] Trial 3 finished with value: 1523.4038096973388 and parameters: {'max_depth': 7, 'learning_rate': 0.20134093273191378, 'n_estimators': 203, 'subsample': 0.9376289931496556, 'colsample_bytree': 0.6641171026606828, 'alpha': 1.5211205235516367, 'lambda': 1.588094408873344}. Best is trial 1 with value: 1517.5700537262016.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:55:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:55:27,780] Trial 4 finished with value: 1524.1447947618283 and parameters: {'max_depth': 7, 'learning_rate': 0.15575218064017576, 'n_estimators': 245, 'subsample': 0.7269552603781995, 'colsample_bytree': 0.8182235450963922, 'alpha': 1.5833545968212004, 'lambda': 7.75906368001924}. Best is trial 1 with value: 1517.5700537262016.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:55:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:55:30,208] Trial 5 finished with value: 1534.0011685926643 and parameters: {'max_depth': 8, 'learning_rate': 0.183115606282805, 'n_estimators': 284, 'subsample': 0.832921499397441, 'colsample_bytree': 0.8313513895733435, 'alpha': 5.439265950876119, 'lambda': 4.0302572625957875}. Best is trial 1 with value: 1517.5700537262016.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:55:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:55:32,122] Trial 6 finished with value: 1515.580284965494 and parameters: {'max_depth': 8, 'learning_rate': 0.0464901768578338, 'n_estimators': 116, 'subsample': 0.8700397977555924, 'colsample_bytree': 0.6747389183957431, 'alpha': 4.159915768096107, 'lambda': 3.2951927192439268}. Best is trial 6 with value: 1515.580284965494.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:55:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:55:33,267] Trial 7 finished with value: 1515.2777624323035 and parameters: {'max_depth': 4, 'learning_rate': 0.2846620638665288, 'n_estimators': 165, 'subsample': 0.9484463014462391, 'colsample_bytree': 0.9524201975271904, 'alpha': 8.374063714964391, 'lambda': 5.81962351141724}. Best is trial 7 with value: 1515.2777624323035.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:55:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:55:35,432] Trial 8 finished with value: 1523.1670225370897 and parameters: {'max_depth': 8, 'learning_rate': 0.15070739479210002, 'n_estimators': 267, 'subsample': 0.9750116960886324, 'colsample_bytree': 0.6434887759277699, 'alpha': 0.7227304726832517, 'lambda': 7.905580129365503}. Best is trial 7 with value: 1515.2777624323035.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:55:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:55:36,817] Trial 9 finished with value: 1515.5929576883593 and parameters: {'max_depth': 5, 'learning_rate': 0.15018475832963107, 'n_estimators': 139, 'subsample': 0.9586727451887078, 'colsample_bytree': 0.94404086076247, 'alpha': 2.110338442504136, 'lambda': 6.29011459683945}. Best is trial 7 with value: 1515.2777624323035.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:55:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:55:37,977] Trial 10 finished with value: 1514.7270915087543 and parameters: {'max_depth': 3, 'learning_rate': 0.276652041483294, 'n_estimators': 51, 'subsample': 0.7053883227178788, 'colsample_bytree': 0.504233025781036, 'alpha': 9.904671076976484, 'lambda': 9.720894670592518}. Best is trial 10 with value: 1514.7270915087543.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:55:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:55:39,558] Trial 11 finished with value: 1514.424781937038 and parameters: {'max_depth': 3, 'learning_rate': 0.2838808993905881, 'n_estimators': 53, 'subsample': 0.699463458946953, 'colsample_bytree': 0.5562440818201126, 'alpha': 9.443380560018799, 'lambda': 9.917148511025122}. Best is trial 11 with value: 1514.424781937038.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:55:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:55:41,255] Trial 12 finished with value: 1515.1647112057383 and parameters: {'max_depth': 3, 'learning_rate': 0.29549668971133225, 'n_estimators': 50, 'subsample': 0.6727493684573568, 'colsample_bytree': 0.5275193733054562, 'alpha': 9.9766560041568, 'lambda': 9.979315715264708}. Best is trial 11 with value: 1514.424781937038.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:55:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:55:42,917] Trial 13 finished with value: 1514.2761297489392 and parameters: {'max_depth': 3, 'learning_rate': 0.2515397779935977, 'n_estimators': 52, 'subsample': 0.6232184526744956, 'colsample_bytree': 0.5144166937578241, 'alpha': 9.613772293846756, 'lambda': 9.613388755918567}. Best is trial 13 with value: 1514.2761297489392.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:55:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:55:44,859] Trial 14 finished with value: 1518.7396387688284 and parameters: {'max_depth': 5, 'learning_rate': 0.2467937958946757, 'n_estimators': 87, 'subsample': 0.5935439783094869, 'colsample_bytree': 0.573240735618163, 'alpha': 8.30360477368077, 'lambda': 8.878835639450806}. Best is trial 13 with value: 1514.2761297489392.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:55:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:55:47,146] Trial 15 finished with value: 1518.2908516012633 and parameters: {'max_depth': 5, 'learning_rate': 0.24465087401874688, 'n_estimators': 81, 'subsample': 0.5213999969642039, 'colsample_bytree': 0.5849139232963185, 'alpha': 7.785291714902616, 'lambda': 8.687904077017096}. Best is trial 13 with value: 1514.2761297489392.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:55:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:55:48,485] Trial 16 finished with value: 1515.6397707057702 and parameters: {'max_depth': 4, 'learning_rate': 0.2357480656595323, 'n_estimators': 78, 'subsample': 0.6428409544489487, 'colsample_bytree': 0.5891108787651547, 'alpha': 6.841541644970034, 'lambda': 6.474313279800851}. Best is trial 13 with value: 1514.2761297489392.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:55:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:55:51,324] Trial 17 finished with value: 1514.1903540578967 and parameters: {'max_depth': 3, 'learning_rate': 0.11461724415351557, 'n_estimators': 152, 'subsample': 0.7908375607253738, 'colsample_bytree': 0.7439436120460602, 'alpha': 9.176283289961027, 'lambda': 9.020947753746473}. Best is trial 17 with value: 1514.1903540578967.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:55:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:55:53,349] Trial 18 finished with value: 1514.1644717572947 and parameters: {'max_depth': 4, 'learning_rate': 0.09101254886674827, 'n_estimators': 168, 'subsample': 0.7801787560085829, 'colsample_bytree': 0.7433861611527428, 'alpha': 6.412541400110548, 'lambda': 5.16696204213291}. Best is trial 18 with value: 1514.1644717572947.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:55:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:55:55,010] Trial 19 finished with value: 1514.307494076501 and parameters: {'max_depth': 4, 'learning_rate': 0.0966892917121416, 'n_estimators': 167, 'subsample': 0.7862064431221495, 'colsample_bytree': 0.750003505823559, 'alpha': 6.136633106783071, 'lambda': 2.121120833732183}. Best is trial 18 with value: 1514.1644717572947.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:55:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:55:57,610] Trial 20 finished with value: 1515.745239551055 and parameters: {'max_depth': 6, 'learning_rate': 0.09749598640049978, 'n_estimators': 131, 'subsample': 0.7742549804228424, 'colsample_bytree': 0.7443344712509823, 'alpha': 3.879875416527408, 'lambda': 0.23306205931753432}. Best is trial 18 with value: 1514.1644717572947.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:55:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:55:58,999] Trial 21 finished with value: 1514.013214480808 and parameters: {'max_depth': 3, 'learning_rate': 0.10405661894649752, 'n_estimators': 153, 'subsample': 0.7752161761547618, 'colsample_bytree': 0.8947056185375043, 'alpha': 8.874255330177858, 'lambda': 5.416130788971767}. Best is trial 21 with value: 1514.013214480808.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:55:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:56:00,833] Trial 22 finished with value: 1514.2906686579831 and parameters: {'max_depth': 4, 'learning_rate': 0.10155184762622335, 'n_estimators': 157, 'subsample': 0.7690771311889034, 'colsample_bytree': 0.9979338097730409, 'alpha': 7.38288641601582, 'lambda': 5.412077032062123}. Best is trial 21 with value: 1514.013214480808.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:56:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:56:02,213] Trial 23 finished with value: 1513.9793502254759 and parameters: {'max_depth': 3, 'learning_rate': 0.1221488414734541, 'n_estimators': 190, 'subsample': 0.8186066832327971, 'colsample_bytree': 0.8886803203145972, 'alpha': 8.787847528600409, 'lambda': 4.676147348112838}. Best is trial 23 with value: 1513.9793502254759.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:56:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:56:04,340] Trial 24 finished with value: 1514.4382021476315 and parameters: {'max_depth': 4, 'learning_rate': 0.015611696409412248, 'n_estimators': 188, 'subsample': 0.8737015046304601, 'colsample_bytree': 0.8826060690683744, 'alpha': 8.721596296362364, 'lambda': 4.5699950837427945}. Best is trial 23 with value: 1513.9793502254759.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:56:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:56:07,385] Trial 25 finished with value: 1514.0713458708744 and parameters: {'max_depth': 5, 'learning_rate': 0.07140096689832373, 'n_estimators': 233, 'subsample': 0.8243132526304855, 'colsample_bytree': 0.8869749727769441, 'alpha': 6.075829489183157, 'lambda': 2.970605002344631}. Best is trial 23 with value: 1513.9793502254759.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:56:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:56:10,625] Trial 26 finished with value: 1516.8650453604805 and parameters: {'max_depth': 6, 'learning_rate': 0.12897758284563207, 'n_estimators': 228, 'subsample': 0.827817951739266, 'colsample_bytree': 0.9106056094715129, 'alpha': 7.608011211894691, 'lambda': 2.548658933775717}. Best is trial 23 with value: 1513.9793502254759.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:56:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:56:13,221] Trial 27 finished with value: 1514.1911383442216 and parameters: {'max_depth': 5, 'learning_rate': 0.07287121198969096, 'n_estimators': 242, 'subsample': 0.8932792256692365, 'colsample_bytree': 0.8751703161299813, 'alpha': 5.435846995331097, 'lambda': 3.1053874746733583}. Best is trial 23 with value: 1513.9793502254759.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:56:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:56:14,944] Trial 28 finished with value: 1516.6809824116272 and parameters: {'max_depth': 6, 'learning_rate': 0.12506159513036952, 'n_estimators': 184, 'subsample': 0.8187995449979825, 'colsample_bytree': 0.9559431197070686, 'alpha': 8.730691120230741, 'lambda': 4.862958085088613}. Best is trial 23 with value: 1513.9793502254759.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:56:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:56:16,288] Trial 29 finished with value: 1513.9838856267525 and parameters: {'max_depth': 3, 'learning_rate': 0.0750507387644175, 'n_estimators': 213, 'subsample': 0.8672903318119951, 'colsample_bytree': 0.7870708514624252, 'alpha': 7.102777950898672, 'lambda': 4.062670540149021}. Best is trial 23 with value: 1513.9793502254759.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:56:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:56:17,686] Trial 30 finished with value: 1514.5095635073214 and parameters: {'max_depth': 3, 'learning_rate': 0.018506935634524352, 'n_estimators': 209, 'subsample': 0.7373032422175392, 'colsample_bytree': 0.9954047780677366, 'alpha': 7.119511283142526, 'lambda': 4.131223049435917}. Best is trial 23 with value: 1513.9793502254759.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:56:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:56:21,329] Trial 31 finished with value: 1526.8471964201206 and parameters: {'max_depth': 10, 'learning_rate': 0.06722638997360732, 'n_estimators': 222, 'subsample': 0.8464393963699984, 'colsample_bytree': 0.7863639733572058, 'alpha': 5.916604806317708, 'lambda': 3.327656697265093}. Best is trial 23 with value: 1513.9793502254759.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:56:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:56:22,768] Trial 32 finished with value: 1514.0892375128876 and parameters: {'max_depth': 3, 'learning_rate': 0.04821697250787157, 'n_estimators': 193, 'subsample': 0.8103674422086653, 'colsample_bytree': 0.8741573909959681, 'alpha': 8.074144989991648, 'lambda': 2.5582742832922527}. Best is trial 23 with value: 1513.9793502254759.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:56:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:56:24,728] Trial 33 finished with value: 1513.9263862070504 and parameters: {'max_depth': 4, 'learning_rate': 0.07852902563294555, 'n_estimators': 242, 'subsample': 0.9101446086535225, 'colsample_bytree': 0.9150058472774392, 'alpha': 4.731227618007625, 'lambda': 4.409154242118149}. Best is trial 33 with value: 1513.9263862070504.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:56:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:56:26,895] Trial 34 finished with value: 1514.1135135016088 and parameters: {'max_depth': 4, 'learning_rate': 0.08118488375372677, 'n_estimators': 259, 'subsample': 0.9147256580585819, 'colsample_bytree': 0.789330524388453, 'alpha': 4.412050647193661, 'lambda': 6.055354817728533}. Best is trial 33 with value: 1513.9263862070504.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:56:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:56:28,613] Trial 35 finished with value: 1514.1590177342819 and parameters: {'max_depth': 3, 'learning_rate': 0.1162118200155656, 'n_estimators': 206, 'subsample': 0.9133669061974152, 'colsample_bytree': 0.9174534971187206, 'alpha': 2.968021656568748, 'lambda': 6.834298646209873}. Best is trial 33 with value: 1513.9263862070504.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:56:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:56:30,303] Trial 36 finished with value: 1514.1431716480263 and parameters: {'max_depth': 3, 'learning_rate': 0.17094732038445123, 'n_estimators': 279, 'subsample': 0.9900789284709233, 'colsample_bytree': 0.8504645070264965, 'alpha': 8.959735599032273, 'lambda': 4.402580806666073}. Best is trial 33 with value: 1513.9263862070504.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:56:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:56:31,934] Trial 37 finished with value: 1514.0258679670703 and parameters: {'max_depth': 4, 'learning_rate': 0.03543677660094981, 'n_estimators': 254, 'subsample': 0.863852568887011, 'colsample_bytree': 0.9171209750586907, 'alpha': 6.683703450747677, 'lambda': 5.53902692500893}. Best is trial 33 with value: 1513.9263862070504.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:56:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:56:33,310] Trial 38 finished with value: 1514.0353975891685 and parameters: {'max_depth': 3, 'learning_rate': 0.053662042516791804, 'n_estimators': 179, 'subsample': 0.8886152250832132, 'colsample_bytree': 0.8538078977300774, 'alpha': 5.042161030047417, 'lambda': 3.624905769608329}. Best is trial 33 with value: 1513.9263862070504.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:56:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:56:35,019] Trial 39 finished with value: 1514.2935676792217 and parameters: {'max_depth': 4, 'learning_rate': 0.13505007490605558, 'n_estimators': 222, 'subsample': 0.9261974918800163, 'colsample_bytree': 0.8025203235449399, 'alpha': 3.332890485352134, 'lambda': 4.873234800777669}. Best is trial 33 with value: 1513.9263862070504.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:56:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:56:38,765] Trial 40 finished with value: 1516.335039989261 and parameters: {'max_depth': 9, 'learning_rate': 0.031371505952962286, 'n_estimators': 296, 'subsample': 0.8519473297319425, 'colsample_bytree': 0.9681384720198115, 'alpha': 7.990461116908315, 'lambda': 7.074309230664183}. Best is trial 33 with value: 1513.9263862070504.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:56:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:56:40,672] Trial 41 finished with value: 1514.0450906682258 and parameters: {'max_depth': 4, 'learning_rate': 0.032712513340379376, 'n_estimators': 255, 'subsample': 0.8543959089474992, 'colsample_bytree': 0.924975786324818, 'alpha': 6.723863012921768, 'lambda': 5.427444523420514}. Best is trial 33 with value: 1513.9263862070504.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:56:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:56:42,110] Trial 42 finished with value: 1513.9816263746413 and parameters: {'max_depth': 4, 'learning_rate': 0.08147335400144395, 'n_estimators': 241, 'subsample': 0.8863407282215554, 'colsample_bytree': 0.8279321050013926, 'alpha': 4.785150983062226, 'lambda': 5.877113421453717}. Best is trial 33 with value: 1513.9263862070504.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:56:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:56:43,662] Trial 43 finished with value: 1513.973757820071 and parameters: {'max_depth': 3, 'learning_rate': 0.08130956647308493, 'n_estimators': 241, 'subsample': 0.8929086857188901, 'colsample_bytree': 0.8178586450434404, 'alpha': 5.388473631421388, 'lambda': 3.883186182627238}. Best is trial 33 with value: 1513.9263862070504.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:56:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:56:45,253] Trial 44 finished with value: 1514.464775540088 and parameters: {'max_depth': 5, 'learning_rate': 0.08163242246179693, 'n_estimators': 239, 'subsample': 0.9455312091924439, 'colsample_bytree': 0.8279686945013172, 'alpha': 4.660336109672001, 'lambda': 3.8286621345571863}. Best is trial 33 with value: 1513.9263862070504.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:56:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:56:46,544] Trial 45 finished with value: 1514.067079045166 and parameters: {'max_depth': 3, 'learning_rate': 0.0579134153907528, 'n_estimators': 270, 'subsample': 0.8918011356034516, 'colsample_bytree': 0.7699721065832191, 'alpha': 3.8607660521398044, 'lambda': 4.249783406343134}. Best is trial 33 with value: 1513.9263862070504.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:56:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:56:48,172] Trial 46 finished with value: 1514.2568260521343 and parameters: {'max_depth': 4, 'learning_rate': 0.1400725919433239, 'n_estimators': 216, 'subsample': 0.9733181976576528, 'colsample_bytree': 0.7062443159340697, 'alpha': 5.416085951374724, 'lambda': 7.6768088266666}. Best is trial 33 with value: 1513.9263862070504.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:56:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:56:50,196] Trial 47 finished with value: 1519.2691793406073 and parameters: {'max_depth': 7, 'learning_rate': 0.11451459462431687, 'n_estimators': 247, 'subsample': 0.9000188480556474, 'colsample_bytree': 0.8355625667426387, 'alpha': 5.059404212988861, 'lambda': 1.2047289925726101}. Best is trial 33 with value: 1513.9263862070504.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:56:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:56:51,470] Trial 48 finished with value: 1514.0192665185639 and parameters: {'max_depth': 3, 'learning_rate': 0.08499540348132367, 'n_estimators': 198, 'subsample': 0.9345485385409542, 'colsample_bytree': 0.8074128996027395, 'alpha': 3.4265062694755386, 'lambda': 4.589144621702965}. Best is trial 33 with value: 1513.9263862070504.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:56:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:56:54,546] Trial 49 finished with value: 1519.3048957953752 and parameters: {'max_depth': 9, 'learning_rate': 0.05943790728333506, 'n_estimators': 272, 'subsample': 0.8735108333555636, 'colsample_bytree': 0.8566041537277898, 'alpha': 4.582103724103569, 'lambda': 3.5595556216048108}. Best is trial 33 with value: 1513.9263862070504.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:56:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:56:56,641] Trial 50 finished with value: 1516.4591362045312 and parameters: {'max_depth': 5, 'learning_rate': 0.2170477350048287, 'n_estimators': 215, 'subsample': 0.95907982639818, 'colsample_bytree': 0.7085151848629625, 'alpha': 0.4906891257293369, 'lambda': 6.513417348460985}. Best is trial 33 with value: 1513.9263862070504.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:56:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:56:58,156] Trial 51 finished with value: 1513.9232374342819 and parameters: {'max_depth': 3, 'learning_rate': 0.10608214221125865, 'n_estimators': 136, 'subsample': 0.8097175072302998, 'colsample_bytree': 0.8217544771745495, 'alpha': 2.2820401586409407, 'lambda': 5.712211784229131}. Best is trial 51 with value: 1513.9232374342819.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:56:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:57:01,601] Trial 52 finished with value: 1513.8670673615482 and parameters: {'max_depth': 3, 'learning_rate': 0.10951546913095321, 'n_estimators': 117, 'subsample': 0.7990037955264295, 'colsample_bytree': 0.8236912001752946, 'alpha': 1.645145878027562, 'lambda': 5.04011646790288}. Best is trial 52 with value: 1513.8670673615482.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:57:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:57:04,294] Trial 53 finished with value: 1514.1474897676162 and parameters: {'max_depth': 3, 'learning_rate': 0.16481965064355514, 'n_estimators': 118, 'subsample': 0.7997492329969136, 'colsample_bytree': 0.8160265370890234, 'alpha': 1.9885991937987915, 'lambda': 6.013312222548018}. Best is trial 52 with value: 1513.8670673615482.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:57:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:57:06,715] Trial 54 finished with value: 1513.8958593435768 and parameters: {'max_depth': 4, 'learning_rate': 0.10670414692021904, 'n_estimators': 125, 'subsample': 0.7560832321060429, 'colsample_bytree': 0.8646615586467609, 'alpha': 1.3663957866117857, 'lambda': 5.759889325563673}. Best is trial 52 with value: 1513.8670673615482.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:57:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:57:08,551] Trial 55 finished with value: 1514.0511909057113 and parameters: {'max_depth': 3, 'learning_rate': 0.10909248097986529, 'n_estimators': 137, 'subsample': 0.707892136358073, 'colsample_bytree': 0.8621576828828638, 'alpha': 1.1170353909008939, 'lambda': 5.080562226255843}. Best is trial 52 with value: 1513.8670673615482.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:57:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:57:10,237] Trial 56 finished with value: 1514.852288926461 and parameters: {'max_depth': 4, 'learning_rate': 0.14447832821123746, 'n_estimators': 98, 'subsample': 0.7592473548181937, 'colsample_bytree': 0.929965597691502, 'alpha': 0.010919662504733418, 'lambda': 4.723085664343132}. Best is trial 52 with value: 1513.8670673615482.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:57:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:57:11,716] Trial 57 finished with value: 1514.1271091241872 and parameters: {'max_depth': 3, 'learning_rate': 0.1230717090009277, 'n_estimators': 97, 'subsample': 0.7332927001806715, 'colsample_bytree': 0.9013475692574914, 'alpha': 2.287244807729704, 'lambda': 6.348199275869684}. Best is trial 52 with value: 1513.8670673615482.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:57:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:57:13,625] Trial 58 finished with value: 1514.1369015861271 and parameters: {'max_depth': 4, 'learning_rate': 0.09302622953115351, 'n_estimators': 123, 'subsample': 0.748719492730451, 'colsample_bytree': 0.7656940228722852, 'alpha': 1.3488991054847819, 'lambda': 5.754421235272121}. Best is trial 52 with value: 1513.8670673615482.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:57:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:57:15,386] Trial 59 finished with value: 1514.234744304194 and parameters: {'max_depth': 3, 'learning_rate': 0.1538976998955841, 'n_estimators': 107, 'subsample': 0.6794365346272169, 'colsample_bytree': 0.8354430222556231, 'alpha': 1.8529360111881235, 'lambda': 5.3156118324820865}. Best is trial 52 with value: 1513.8670673615482.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:57:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:57:17,056] Trial 60 finished with value: 1514.138136794254 and parameters: {'max_depth': 4, 'learning_rate': 0.1039295465209778, 'n_estimators': 145, 'subsample': 0.8355369154653036, 'colsample_bytree': 0.8698051350542335, 'alpha': 2.571209040577429, 'lambda': 4.967482550044749}. Best is trial 52 with value: 1513.8670673615482.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:57:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:57:18,878] Trial 61 finished with value: 1513.9291146393637 and parameters: {'max_depth': 4, 'learning_rate': 0.09542012576045386, 'n_estimators': 125, 'subsample': 0.8057752823933789, 'colsample_bytree': 0.8213580616726477, 'alpha': 1.0951393687327446, 'lambda': 5.873850573987818}. Best is trial 52 with value: 1513.8670673615482.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:57:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:57:20,900] Trial 62 finished with value: 1514.0596436930934 and parameters: {'max_depth': 3, 'learning_rate': 0.13182855398804863, 'n_estimators': 125, 'subsample': 0.8084703469320942, 'colsample_bytree': 0.8881206247640459, 'alpha': 0.9887546640841873, 'lambda': 6.648979348343564}. Best is trial 52 with value: 1513.8670673615482.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:57:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:57:22,484] Trial 63 finished with value: 1514.1684636969765 and parameters: {'max_depth': 5, 'learning_rate': 0.08926562432463088, 'n_estimators': 107, 'subsample': 0.7998686252917113, 'colsample_bytree': 0.8446325101153885, 'alpha': 1.6612914488460526, 'lambda': 5.7311192970362015}. Best is trial 52 with value: 1513.8670673615482.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:57:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:57:24,010] Trial 64 finished with value: 1514.490696315482 and parameters: {'max_depth': 4, 'learning_rate': 0.11713209047350492, 'n_estimators': 134, 'subsample': 0.7168089617386845, 'colsample_bytree': 0.8158174084535565, 'alpha': 0.5007351953157632, 'lambda': 7.533669051135101}. Best is trial 52 with value: 1513.8670673615482.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:57:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:57:26,597] Trial 65 finished with value: 1523.8404824871827 and parameters: {'max_depth': 8, 'learning_rate': 0.10789240056095803, 'n_estimators': 147, 'subsample': 0.7556337333019398, 'colsample_bytree': 0.938729448711983, 'alpha': 2.454252361547038, 'lambda': 3.882877378935318}. Best is trial 52 with value: 1513.8670673615482.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:57:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:57:28,084] Trial 66 finished with value: 1513.9642738263371 and parameters: {'max_depth': 3, 'learning_rate': 0.0995669435036691, 'n_estimators': 65, 'subsample': 0.7903911411290291, 'colsample_bytree': 0.7239924489410134, 'alpha': 1.3675920752021196, 'lambda': 4.4580379221770485}. Best is trial 52 with value: 1513.8670673615482.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:57:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:57:29,772] Trial 67 finished with value: 1514.0476896454022 and parameters: {'max_depth': 4, 'learning_rate': 0.09416998408787733, 'n_estimators': 74, 'subsample': 0.7881450117004587, 'colsample_bytree': 0.6731472060530175, 'alpha': 1.2889197851300924, 'lambda': 4.293314515824637}. Best is trial 52 with value: 1513.8670673615482.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:57:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2025-02-17 11:57:31,218] Trial 68 finished with value: 1514.1968442188204 and parameters: {'max_depth': 3, 'learning_rate': 0.06294263139815073, 'n_estimators': 162, 'subsample': 0.5112827563755672, 'colsample_bytree': 0.728370449241041, 'alpha': 0.8258770304572788, 'lambda': 8.066193025622807}. Best is trial 52 with value: 1513.8670673615482.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a study object and optimize the objective function\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'max_depth': 3, 'learning_rate': 0.10951546913095321, 'n_estimators': 117, 'subsample': 0.7990037955264295, 'colsample_bytree': 0.8236912001752946, 'alpha': 1.645145878027562, 'lambda': 5.04011646790288}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:57:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Root Mean Squared Error: 38.911478482605396\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print the best hyperparameters\n",
    "print(f\"Best hyperparameters: {study.best_params}\")\n",
    "\n",
    "# Train the final model with the best hyperparameters\n",
    "best_params = study.best_params\n",
    "dtrain = xgb.DMatrix(X_train_scaled, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test_scaled, label=y_test)\n",
    "final_model = xgb.train(best_params, dtrain, num_boost_round=50)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = final_model.predict(dtest)\n",
    "\n",
    "# Evaluate the final model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mse ** 0.5\n",
    "\n",
    "print(f\"Final Root Mean Squared Error: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After 100 trials using optuna the lowest rMSE obtained was 38.9062, which is a very close result to the one accomplished by using ligthGBM but still far from reaching the competition winner(38.82005) :("
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
